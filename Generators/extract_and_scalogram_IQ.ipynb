{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Combined Data Extractor & IQ Scalogram Generator\n",
                "\n",
                "This notebook extracts data from the RadioML HDF5 dataset and generates IQ scalograms in a single pipeline.\n",
                "\n",
                "**Output:** `[224 x 224 x 2]` NumPy arrays where:\n",
                "- Channel 0: CWT of In-Phase (I) component\n",
                "- Channel 1: CWT of Quadrature (Q) component"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import h5py\n",
                "import json\n",
                "import numpy as np\n",
                "import pywt\n",
                "import cv2\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ======================\n",
                "# CONFIGURATION\n",
                "# ======================\n",
                "\n",
                "# Input HDF5 file path\n",
                "HDF5_FILE = \"Dataset/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
                "CLASSES_JSON = \"Dataset/classes-fixed.json\"\n",
                "\n",
                "# Output directory for scalograms\n",
                "OUTPUT_DIR = \"Dataset/Scalograms\"\n",
                "\n",
                "# SNR levels to process (-20 to 30 dB in steps of 2)\n",
                "SNR_VALUES = [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
                "\n",
                "# Classes to process (subset or all)\n",
                "# Set to None to use all classes from JSON, or specify a list\n",
                "SELECTED_CLASSES = [\n",
                "    \"OOK\", \"4ASK\", \"BPSK\", \"QPSK\", \"8PSK\", \"8ASK\", \"16APSK\", \"64QAM\",\n",
                "    \"AM-SSB-WC\", \"AM-DSB-WC\", \"FM\", \"GMSK\", \"OQPSK\"\n",
                "]\n",
                "\n",
                "# Processing limits\n",
                "MAX_FRAMES_PER_CLASS_SNR = 200  # Set to None to process all 4096 frames\n",
                "\n",
                "# Visual debugging\n",
                "SAVE_SAMPLES = True\n",
                "NUM_SAMPLES = 3  # Number of debug images per class\n",
                "SAMPLES_DIR = \"Dataset/Samples\"\n",
                "\n",
                "print(f\"HDF5 File: {HDF5_FILE}\")\n",
                "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
                "print(f\"SNR Levels: {len(SNR_VALUES)} levels from {SNR_VALUES[0]} to {SNR_VALUES[-1]} dB\")\n",
                "print(f\"Selected Classes: {SELECTED_CLASSES}\")\n",
                "print(f\"Max Frames per Class-SNR: {MAX_FRAMES_PER_CLASS_SNR or 'All (4096)'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load HDF5 Dataset Info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load class names\n",
                "with open(CLASSES_JSON, 'r') as f:\n",
                "    all_class_names = json.load(f)\n",
                "\n",
                "print(f\"All modulation classes ({len(all_class_names)}): {all_class_names}\")\n",
                "\n",
                "# Filter to selected classes if specified\n",
                "if SELECTED_CLASSES:\n",
                "    class_names = SELECTED_CLASSES\n",
                "    # Get indices of selected classes in the original list\n",
                "    class_indices = {name: all_class_names.index(name) for name in SELECTED_CLASSES if name in all_class_names}\n",
                "else:\n",
                "    class_names = all_class_names\n",
                "    class_indices = {name: i for i, name in enumerate(all_class_names)}\n",
                "\n",
                "print(f\"\\nProcessing classes ({len(class_names)}): {class_names}\")\n",
                "print(f\"Class indices in HDF5: {class_indices}\")\n",
                "\n",
                "# Verify HDF5 file structure\n",
                "with h5py.File(HDF5_FILE, 'r') as hdf:\n",
                "    print(f\"\\nHDF5 Keys: {list(hdf.keys())}\")\n",
                "    print(f\"X shape: {hdf['X'].shape} (frames, samples, I/Q)\")\n",
                "    print(f\"Y shape: {hdf['Y'].shape} (frames, one-hot labels)\")\n",
                "    print(f\"Z shape: {hdf['Z'].shape} (frames, SNR)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_cwt(signal, sampling_rate=1e6, wavelet='cmor1.5-0.5'):\n",
                "    \"\"\"\n",
                "    Compute Continuous Wavelet Transform for a 1D signal.\n",
                "    Returns magnitude of CWT coefficients.\n",
                "    \"\"\"\n",
                "    sampling_period = 1 / sampling_rate\n",
                "    scales = np.logspace(0.2, 1.5, num=224)\n",
                "    coeffs, _ = pywt.cwt(signal, scales, wavelet, sampling_period=sampling_period)\n",
                "    return np.abs(coeffs)\n",
                "\n",
                "\n",
                "def process_frame_to_scalogram(i_signal, q_signal):\n",
                "    \"\"\"\n",
                "    Convert I/Q signals to dual-channel scalogram.\n",
                "    Returns array of shape [224, 224, 2].\n",
                "    \"\"\"\n",
                "    # Compute CWT for I and Q channels\n",
                "    cwt_i = compute_cwt(i_signal)\n",
                "    cwt_q = compute_cwt(q_signal)\n",
                "    \n",
                "    # Resize to 224x224\n",
                "    cwt_i = cv2.resize(cwt_i, (224, 224), interpolation=cv2.INTER_LANCZOS4)\n",
                "    cwt_q = cv2.resize(cwt_q, (224, 224), interpolation=cv2.INTER_LANCZOS4)\n",
                "    \n",
                "    # Stack channels: [224, 224, 2]\n",
                "    scalogram = np.stack([cwt_i, cwt_q], axis=-1)\n",
                "    \n",
                "    return scalogram.astype(np.float32)\n",
                "\n",
                "\n",
                "def save_debug_image(cwt_i, cwt_q, save_path):\n",
                "    \"\"\"\n",
                "    Save visual comparison of I and Q channels (side-by-side grayscale).\n",
                "    \"\"\"\n",
                "    def normalize_to_img(arr):\n",
                "        arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
                "        return (arr * 255).astype(np.uint8)\n",
                "    \n",
                "    img_i = normalize_to_img(cwt_i)\n",
                "    img_q = normalize_to_img(cwt_q)\n",
                "    \n",
                "    # Stack side-by-side: Left = I, Right = Q\n",
                "    combined = np.hstack([img_i, img_q])\n",
                "    cv2.imwrite(save_path, combined)\n",
                "\n",
                "\n",
                "print(\"Helper functions defined ✓\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Output Directory Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create output directories\n",
                "for snr in SNR_VALUES:\n",
                "    for class_name in class_names:\n",
                "        os.makedirs(os.path.join(OUTPUT_DIR, f\"snr_{snr}\", class_name), exist_ok=True)\n",
                "        if SAVE_SAMPLES:\n",
                "            os.makedirs(os.path.join(SAMPLES_DIR, f\"snr_{snr}\", class_name), exist_ok=True)\n",
                "\n",
                "print(f\"Created directory structure for {len(SNR_VALUES)} SNR levels × {len(class_names)} classes\")\n",
                "print(f\"Output path: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Processing Pipeline\n",
                "\n",
                "Extract data from HDF5 and generate scalograms in one pass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_and_generate_scalograms():\n",
                "    \"\"\"\n",
                "    Main pipeline: Read HDF5 -> Extract I/Q -> Compute CWT -> Save Scalograms\n",
                "    \"\"\"\n",
                "    frames_per_snr_class = 4096  # Fixed in RadioML dataset\n",
                "    max_frames = MAX_FRAMES_PER_CLASS_SNR if MAX_FRAMES_PER_CLASS_SNR else frames_per_snr_class\n",
                "    \n",
                "    total_processed = 0\n",
                "    \n",
                "    with h5py.File(HDF5_FILE, 'r') as hdf:\n",
                "        X = hdf['X']  # I/Q data: shape (N, 1024, 2)\n",
                "        Y = hdf['Y']  # One-hot labels\n",
                "        Z = hdf['Z']  # SNR values\n",
                "        \n",
                "        # Process each selected class\n",
                "        for class_name in class_names:\n",
                "            class_idx = class_indices[class_name]\n",
                "            \n",
                "            print(f\"\\n{'='*50}\")\n",
                "            print(f\"Processing: {class_name} (index {class_idx})\")\n",
                "            print(f\"{'='*50}\")\n",
                "            \n",
                "            # For each SNR level\n",
                "            for snr_idx, snr in enumerate(SNR_VALUES):\n",
                "                \n",
                "                # Calculate frame indices in HDF5\n",
                "                # Data is organized: [class_0_snr_-20, class_0_snr_-18, ..., class_1_snr_-20, ...]\n",
                "                start_idx = (class_idx * len(SNR_VALUES) * frames_per_snr_class) + \\\n",
                "                            (snr_idx * frames_per_snr_class)\n",
                "                \n",
                "                output_dir = os.path.join(OUTPUT_DIR, f\"snr_{snr}\", class_name)\n",
                "                sample_dir = os.path.join(SAMPLES_DIR, f\"snr_{snr}\", class_name) if SAVE_SAMPLES else None\n",
                "                \n",
                "                sample_count = 0\n",
                "                processed = 0\n",
                "                \n",
                "                # Process frames\n",
                "                for frame_num in tqdm(range(min(max_frames, frames_per_snr_class)), \n",
                "                                      desc=f\"SNR {snr:3d} dB\", leave=False):\n",
                "                    \n",
                "                    frame_idx = start_idx + frame_num\n",
                "                    \n",
                "                    # Load I/Q data\n",
                "                    frame_data = X[frame_idx]  # Shape: (1024, 2)\n",
                "                    i_signal = frame_data[:, 0]\n",
                "                    q_signal = frame_data[:, 1]\n",
                "                    \n",
                "                    # Verify label and SNR (optional sanity check)\n",
                "                    actual_label = np.argmax(Y[frame_idx])\n",
                "                    actual_snr = Z[frame_idx][0]\n",
                "                    if actual_label != class_idx or actual_snr != snr:\n",
                "                        print(f\"[WARN] Mismatch at idx {frame_idx}: expected {class_idx}/{snr}, got {actual_label}/{actual_snr}\")\n",
                "                        continue\n",
                "                    \n",
                "                    # Generate scalogram\n",
                "                    scalogram = process_frame_to_scalogram(i_signal, q_signal)\n",
                "                    \n",
                "                    # Save scalogram\n",
                "                    save_path = os.path.join(output_dir, f\"frame_{frame_num}.npy\")\n",
                "                    np.save(save_path, scalogram)\n",
                "                    \n",
                "                    # Save debug image\n",
                "                    if SAVE_SAMPLES and sample_count < NUM_SAMPLES:\n",
                "                        cwt_i = scalogram[:, :, 0]\n",
                "                        cwt_q = scalogram[:, :, 1]\n",
                "                        img_path = os.path.join(sample_dir, f\"frame_{frame_num}_IQ.png\")\n",
                "                        save_debug_image(cwt_i, cwt_q, img_path)\n",
                "                        sample_count += 1\n",
                "                    \n",
                "                    processed += 1\n",
                "                \n",
                "                total_processed += processed\n",
                "                print(f\"  SNR {snr:3d} dB: {processed} scalograms saved\")\n",
                "            \n",
                "            print(f\"✓ Completed {class_name}\")\n",
                "    \n",
                "    return total_processed\n",
                "\n",
                "print(\"Pipeline function defined ✓\")\n",
                "print(f\"\\nReady to process:\")\n",
                "print(f\"  - {len(class_names)} classes\")\n",
                "print(f\"  - {len(SNR_VALUES)} SNR levels\")\n",
                "print(f\"  - Up to {MAX_FRAMES_PER_CLASS_SNR or 4096} frames per class-SNR combination\")\n",
                "expected_total = len(class_names) * len(SNR_VALUES) * (MAX_FRAMES_PER_CLASS_SNR or 4096)\n",
                "print(f\"  - Total expected: {expected_total:,} scalograms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run the Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute the pipeline\n",
                "print(\"Starting extraction and scalogram generation...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "total = extract_and_generate_scalograms()\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(f\"✅ COMPLETE: Generated {total:,} IQ scalograms\")\n",
                "print(f\"Output location: {os.path.abspath(OUTPUT_DIR)}\")\n",
                "if SAVE_SAMPLES:\n",
                "    print(f\"Sample images: {os.path.abspath(SAMPLES_DIR)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verify Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick verification\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Load a random sample to verify\n",
                "test_snr = 10\n",
                "test_class = class_names[0]\n",
                "test_path = os.path.join(OUTPUT_DIR, f\"snr_{test_snr}\", test_class, \"frame_0.npy\")\n",
                "\n",
                "if os.path.exists(test_path):\n",
                "    sample = np.load(test_path)\n",
                "    print(f\"Sample loaded: {test_path}\")\n",
                "    print(f\"Shape: {sample.shape}\")\n",
                "    print(f\"Dtype: {sample.dtype}\")\n",
                "    print(f\"Value range: [{sample.min():.4f}, {sample.max():.4f}]\")\n",
                "    \n",
                "    # Visualize\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "    axes[0].imshow(sample[:, :, 0], aspect='auto', cmap='viridis')\n",
                "    axes[0].set_title(f'{test_class} @ {test_snr}dB - I Channel')\n",
                "    axes[0].set_xlabel('Time')\n",
                "    axes[0].set_ylabel('Frequency (Scale)')\n",
                "    \n",
                "    axes[1].imshow(sample[:, :, 1], aspect='auto', cmap='viridis')\n",
                "    axes[1].set_title(f'{test_class} @ {test_snr}dB - Q Channel')\n",
                "    axes[1].set_xlabel('Time')\n",
                "    axes[1].set_ylabel('Frequency (Scale)')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(f\"Test file not found: {test_path}\")\n",
                "    print(\"Run the pipeline first.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}